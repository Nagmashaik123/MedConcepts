{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TweetSimilarityCheckSample.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzgVHp73iF9ZAqK5a30erT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nagmashaik123/MedConcepts/blob/main/TweetSimilarityCheckSample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "PYSyFcg3WL_K",
        "outputId": "1b195ed5-b0a7-4d71-d539-e313347317d8"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('TweetSimilarityCheckSample.csv')\n",
        "df"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CUID</th>\n",
              "      <th>Concept</th>\n",
              "      <th>Definition</th>\n",
              "      <th>TweetText</th>\n",
              "      <th>HashTags</th>\n",
              "      <th>CleanedTweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C0863129</td>\n",
              "      <td>AGEP</td>\n",
              "      <td>Acute generalized exanthematous pustulosis (AG...</td>\n",
              "      <td>['#ArchivoGeneralEstadoPuebla #AGEP #Puebla #A...</td>\n",
              "      <td>['ArchivoGeneralEstadoPuebla, AGEP, Puebla, Ar...</td>\n",
              "      <td>['archivogeneralestadopuebla age preble archiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C1302752</td>\n",
              "      <td>Abrasion</td>\n",
              "      <td>\\nan abraded area of the skin or mucous membrane</td>\n",
              "      <td>[\"Unfortunately, there's no evidence to sugges...</td>\n",
              "      <td>['banana, whitenteeth, dentalhealth, smile, ab...</td>\n",
              "      <td>['unfortunately there no evidence to suggest t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C0000833</td>\n",
              "      <td>Abscess</td>\n",
              "      <td>\\nAccumulation of purulent material in tissues...</td>\n",
              "      <td>['Yank that impacted tooth before it becomes a...</td>\n",
              "      <td>['abscess, Traitor', 'Abscess, SewerRunsThroug...</td>\n",
              "      <td>['bank that impacted tooth before it becomes a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C0234238</td>\n",
              "      <td>Ache</td>\n",
              "      <td>A dull persistent (usually moderately intense)...</td>\n",
              "      <td>['#strength the #aerialstraps way! I #ache tod...</td>\n",
              "      <td>['strength, aerialstraps, ache, calesthenics, ...</td>\n",
              "      <td>['strength the aerialstraps way i ache today c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C0001122</td>\n",
              "      <td>Acidosis</td>\n",
              "      <td>pathologic condition resulting from accumulati...</td>\n",
              "      <td>[\"Gain new insights in tumor microenvironment ...</td>\n",
              "      <td>['invivoimaging, FLI, fluorescenceimaging, tum...</td>\n",
              "      <td>['gain new insight in tumor microenvironment c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       CUID  ...                                       CleanedTweet\n",
              "0  C0863129  ...  ['archivogeneralestadopuebla age preble archiv...\n",
              "1  C1302752  ...  ['unfortunately there no evidence to suggest t...\n",
              "2  C0000833  ...  ['bank that impacted tooth before it becomes a...\n",
              "3  C0234238  ...  ['strength the aerialstraps way i ache today c...\n",
              "4  C0001122  ...  ['gain new insight in tumor microenvironment c...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFfBQ48fWS09"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj9QZiazWP09"
      },
      "source": [
        "#!pip install -U sentence-transformers\n",
        "import csv\n",
        "#download a pretrained model.\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
        "\n",
        "# Example in semantic search\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "file = open('TweetSimilarityCheckScore.csv', 'w')\n",
        "# create the csv writer\n",
        "writer = csv.writer(file)\n",
        "# write a row to the csv file\n",
        "writer.writerow(['Index','CUID', 'Concept','Definition','TweetText','HashTags','CleanedTweet','Score'])\n",
        "\n",
        "embedder = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
        "\n",
        "# Corpus with example sentences (Tweets collected)\n",
        "count=0\n",
        "scoreList=[]\n",
        "for ind in df.index:\n",
        "  eachTweetList = df[\"CleanedTweet\"][ind].replace(\"'\", \"\")\n",
        "  eachTweetList = eachTweetList[1:-1].split(\",\")\n",
        "  corpus_embeddings = embedder.encode(eachTweetList, convert_to_tensor=True)\n",
        "  # Query sentences (Definitions)\n",
        "  query = df['Definition'][ind]\n",
        "  # Find the closest sentences of the corpus for each query sentence based on cosine similarity\n",
        "  top_k = len(eachTweetList)   # it depends on us\n",
        "  #for query in queries:\n",
        "  query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
        "  cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "  cos_scores = cos_scores.cpu()\n",
        "  #We use torch.topk to find the highest 5 scores\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "\n",
        "  print(\"\\n\\n======================\\n\\n\")\n",
        "  #print(\"Query:\", query)\n",
        "  print(\"\\nTop most similar sentences in corpus:\")\n",
        "  scoreDict={}\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    print(eachTweetList[idx], \"(Score: %.4f)\" % (score))\n",
        "    scoreDict={\"CUID\":df[\"CUID\"][ind], \"Concept\": df[\"Concept\"][ind], \"Definition\":df['Definition'][ind],\"CleanTweet\":eachTweetList[idx],\"Score\":\"%.4f\" % score}\n",
        "    scoreList.append(scoreDict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LGtVF9sVPvj"
      },
      "source": [
        "import pandas as pd\n",
        "df= pd.read_csv('Cleaned_tweets.csv')\n",
        "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQCVrBSRUFYm"
      },
      "source": [
        "count=0\n",
        "file = open('TweetSimilarityCheckScore.csv', 'w')\n",
        "# create the csv writer\n",
        "writer = csv.writer(file)\n",
        "# write a row to the csv file\n",
        "writer.writerow(['Index','CUID', 'Concept','Definition','TweetText','HashTags','CleanedTweet','Score'])\n",
        "\n",
        "for ind in df.index:\n",
        "  \n",
        "\n",
        "  if df['cui'][ind] in $.:\n",
        "    writer.writerow([count,df['cui'][ind], df['concepts'][ind],row[3],df['tweets'][ind],df['hashtags'][ind],df['cleanedtweets'][ind],scoreDict[]])\n",
        "    count=count+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fi5XwrvV283"
      },
      "source": [
        "df=df.sort_values(['Score'],ascending=False).groupby('CUID')\n",
        "df.to_csv('TweetSimilarityCheckScore.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}